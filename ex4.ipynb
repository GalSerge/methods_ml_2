{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "introduction-tensorflow",
      "graded_item_id": "1kAlw",
      "launcher_item_id": "PNLYD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GalSerge/methods_ml_2/blob/main/ex4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UncprnB0ymAE"
      },
      "source": [
        "Ниже приведен код со ссылкой на набор данных «happy» или «sad», содержащий 80 изображений, 40 счастливых и 40 грустных.\n",
        "Создайте сверточную нейронную сеть, которая обучается со 100% точностью на этих изображениях, с отменой обучения при достижении точности обучения .999"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ALIEF4A2tTr",
        "outputId": "37c2bc7f-0fab-4e6e-9f61-4b662bfac696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "#\n",
        "!wget --no-check-certificate \"https://github.com/andrew-veriga/Tensorflow-labs/raw/master/happy-or-sad.zip\" \\\n",
        "   -O \"/tmp/happy-or-sad.zip\"\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-12 12:18:25--  https://github.com/andrew-veriga/Tensorflow-labs/raw/master/happy-or-sad.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/andrew-veriga/Tensorflow-labs/master/happy-or-sad.zip [following]\n",
            "--2024-04-12 12:18:26--  https://raw.githubusercontent.com/andrew-veriga/Tensorflow-labs/master/happy-or-sad.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2670333 (2.5M) [application/zip]\n",
            "Saving to: ‘/tmp/happy-or-sad.zip’\n",
            "\n",
            "/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-04-12 12:18:26 (176 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/h-or-s\")\n",
        "zip_ref.close()\n",
        "\n",
        "import os\n",
        "\n",
        "train_happy_dir = os.path.join('/tmp/h-or-s/happy')\n",
        "\n",
        "train_sad_dir = os.path.join('/tmp/h-or-s/sad')\n",
        "\n",
        "train_happy_names = os.listdir(train_happy_dir)\n",
        "print(train_happy_names[:10])\n",
        "\n",
        "train_sad_names = os.listdir(train_sad_dir)\n",
        "print(train_sad_names[:10])"
      ],
      "metadata": {
        "id": "sv4QjJ3MKOfn",
        "outputId": "f4c28a46-a572-47b0-f1ea-de040ffc99be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy1-17.png', 'happy2-13.png', 'happy2-16.png', 'happy2-07.png', 'happy1-18.png', 'happy2-17.png', 'happy2-01.png', 'happy1-06.png', 'happy1-11.png', 'happy2-02.png']\n",
            "['sad2-01.png', 'sad2-15.png', 'sad2-11.png', 'sad1-08.png', 'sad1-05.png', 'sad1-19.png', 'sad2-08.png', 'sad1-04.png', 'sad2-00.png', 'sad2-02.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11_S4Hd66Lqd",
        "outputId": "7b82d9cb-de7b-4396-cf17-2be59385d54f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "train_happy_dir = os.path.join('/tmp/h-or-s/happy')\n",
        "\n",
        "train_sad_dir = os.path.join('/tmp/h-or-s/sad')\n",
        "\n",
        "train_happy_names = os.listdir(train_happy_dir)\n",
        "print(train_happy_names[:10])\n",
        "\n",
        "train_sad_names = os.listdir(train_sad_dir)\n",
        "print(train_sad_names[:10])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['happy1-17.png', 'happy2-13.png', 'happy2-16.png', 'happy2-07.png', 'happy1-18.png', 'happy2-17.png', 'happy2-01.png', 'happy1-06.png', 'happy1-11.png', 'happy2-02.png']\n",
            "['sad2-01.png', 'sad2-15.png', 'sad2-11.png', 'sad1-08.png', 'sad1-05.png', 'sad1-19.png', 'sad2-08.png', 'sad1-04.png', 'sad2-00.png', 'sad2-02.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StopOnPoint(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, point):\n",
        "        super(StopOnPoint, self).__init__()\n",
        "        self.point = point\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        accuracy = logs['accuracy']\n",
        "        if accuracy >= self.point:\n",
        "            self.model.stop_training = True"
      ],
      "metadata": {
        "id": "NrBO3RroN-Iv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gZoRjft2tTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "475a67a3-deff-4150-e150-606e96796f60"
      },
      "source": [
        "DESIRED_ACCURACY = 0.999\n",
        "\n",
        "callbacks = StopOnPoint(DESIRED_ACCURACY)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/tmp/h-or-s',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=80,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "model.fit(train_generator, epochs=10, callbacks=[callbacks])\n",
        "print('Достигнута точность 99.9%, поэтому обучение закончено!')\n",
        "\n",
        "loss, accuracy = model.evaluate(train_generator)\n",
        "print(f'Точность на обучающих данных: {accuracy*100:.2f}%')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 80 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.6892 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.6884 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6852 - accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6805 - accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6685 - accuracy: 0.9250\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.6564 - accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6403 - accuracy: 1.0000\n",
            "Достигнута точность 99.9%, поэтому обучение закончено!\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6149 - accuracy: 1.0000\n",
            "Точность на обучающих данных: 100.00%\n"
          ]
        }
      ]
    }
  ]
}